{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/train\")[0])\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"53cd84dd8190c3b61869e5c6e364ef71618d0803.tif\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch\n!pip install torchsummary\nfrom efficientnet_pytorch import EfficientNet\nimport torchvision\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchsummary import summary\nimport torch.optim as optim\nimport copy\nimport os\nimport torch\nfrom tqdm.autonotebook import tqdm\nfrom torch.optim.lr_scheduler import _LRScheduler\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torch.utils.data import Dataset","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting efficientnet_pytorch\n  Downloading https://files.pythonhosted.org/packages/06/ff/881afd965c46b11fc6f3c8316de9e08d37fc3b71056dbab861b76faee6ca/efficientnet_pytorch-0.1.0-py3-none-any.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from efficientnet_pytorch) (1.0.1.post2)\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.1.0\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nCollecting torchsummary\n  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/train_labels.csv')\ntrain_csv.head(10)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                         id  label\n0  f38a6374c348f90b587e046aac6079959adf3835      0\n1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n2  755db6279dae599ebb4d39a9123cce439965282d      0\n3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n4  068aba587a4950175d04c680d38943fd488d6a9d      0\n5  acfe80838488fae3c89bd21ade75be5c34e66be7      0\n6  a24ce148f6ffa7ef8eefb4efb12ebffe8dd700da      1\n7  7f6ccae485af121e0b6ee733022e226ee6b0c65f      1\n8  559e55a64c9ba828f700e948f6886f4cea919261      0\n9  8eaaa7a400aa79d36c2440a4aa101cc14256cda4      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>acfe80838488fae3c89bd21ade75be5c34e66be7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>a24ce148f6ffa7ef8eefb4efb12ebffe8dd700da</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7f6ccae485af121e0b6ee733022e226ee6b0c65f</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>559e55a64c9ba828f700e948f6886f4cea919261</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8eaaa7a400aa79d36c2440a4aa101cc14256cda4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = train_csv['label'].unique()\nencoder = {0:'negative',1:'positive'}","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,val_df = train_test_split(train_csv,test_size = 0.2)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class cancer_dataset(Dataset):\n  def __init__(self,image_dir,train_csv,transform = None):\n    self.img_dir = image_dir\n    self.transform = transform\n    self.id = train_csv.iloc[:,0]\n    self.classes =  train_csv.iloc[:,1]\n  def __len__(self):\n    return len(self.id)\n  def __getitem__(self,idx):\n    img_name = os.path.join(self.img_dir, self.id[idx]+'.tif')\n    image = cv2.imread(img_name)\n    if self.transform:\n        image = self.transform(image)\n    label = self.classes[idx]\n    return image,label","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Dataset\nimport os\nfrom tqdm.autonotebook import tqdm\nimport numpy as np\nfrom torch.utils.data.sampler import SubsetRandomSampler\n#data loader\n\ndef data_loader(train_data,encoder,test_data = None,valid_data = None , valid_size = None,test_size = None , batch_size = 32,inv_normalize = None):\n    #class_plot(train_data,encoder,inv_normalize)\n    if(test_data == None and valid_size == None and valid_data == None and test_size == None):\n        train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)\n        dataloaders = {'train':train_loader}\n        return dataloaders\n    if(test_data !=None and valid_size==None and valid_data == None):\n        test_loader = DataLoader(test_data, batch_size= batch_size,shuffle = True)\n        train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)\n\n        dataloaders = {'train':train_loader,'test':test_loader}\n\n    if(test_data == None and valid_size!=None and valid_data == None):\n        if(test_size==None):\n            data_len = len(train_data)\n            indices = list(range(data_len))\n            np.random.shuffle(indices)\n            split1 = int(np.floor(valid_size * data_len))\n            valid_idx , train_idx = indices[:split1], indices[split1:]\n            valid_sampler = SubsetRandomSampler(valid_idx)\n            train_sampler = SubsetRandomSampler(train_idx)\n            valid_loader = DataLoader(train_data, batch_size= batch_size, sampler=valid_sampler)\n            train_loader =  DataLoader(train_data, batch_size = batch_size , sampler=valid_sampler)\n            dataloaders = {'train':train_loader,'val':valid_loader}\n            return dataloaders\n        if(test_size !=None):\n            data_len = len(train_data)\n            indices = list(range(data_len))\n            np.random.shuffle(indices)\n            split1 = int(np.floor(valid_size * data_len))\n            split2 = int(np.floor(test_size * data_len))\n            valid_idx , test_idx,train_idx = indices[:split1], indices[split1:split1+split2],indices[split1+split2:]\n            valid_sampler = SubsetRandomSampler(valid_idx)\n            test_sampler = SubsetRandomSampler(test_idx)\n            train_sampler = SubsetRandomSampler(train_idx)\n            valid_loader = DataLoader(test_data, batch_size= batch_size, sampler=valid_sampler)\n            test_loader = DataLoader(test_data, batch_size= batch_size, sampler=test_sampler)\n            train_loader =  DataLoader(train_data, batch_size = batch_size , sampler=valid_sampler)\n            dataloaders = {'train':train_loader,'val':valid_loader,'test':test_loader}\n            return dataloaders\n    if(test_data != None and valid_size!=None):\n        data_len = len(test_data)\n        indices = list(range(data_len))\n        np.random.shuffle(indices)\n        split1 = int(np.floor(valid_size * data_len))\n        valid_idx , test_idx = indices[:split1], indices[split1:]\n        valid_sampler = SubsetRandomSampler(valid_idx)\n        test_sampler = SubsetRandomSampler(test_idx)\n        valid_loader = DataLoader(test_data, batch_size= batch_size, sampler=valid_sampler)\n        test_loader = DataLoader(test_data, batch_size= batch_size, sampler=test_sampler)\n        train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)\n\n        dataloaders = {'train':train_loader,'val':valid_loader,'test':test_loader}\n        return dataloaders\n    if(test_data!=None and valid_data !=None):\n        valid_loader = DataLoader(valid_data, batch_size= batch_size,shuffle  = True)\n        test_loader = DataLoader(test_data, batch_size= batch_size,shuffle = True)\n        train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)\n\n        dataloaders = {'train':train_loader,'val':valid_loader,'test':test_loader}\n        return dataloaders\ndef normalization_parameter(dataloader):\n    mean = 0.\n    std = 0.\n    nb_samples = len(dataloader.dataset)\n    for data,_ in tqdm(dataloader):\n        batch_samples = data.size(0)\n        data = data.view(batch_samples, data.size(1), -1)\n        mean += data.mean(2).sum(0)\n        std += data.std(2).sum(0)\n    mean /= nb_samples\n    std /= nb_samples\n    return mean,std","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_size = 32\nbatch_size = 128\n\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\ntrain_transforms = transforms.Compose([\n                                        transforms.ToPILImage(),\n                                        transforms.Resize((im_size,im_size)),\n                                        transforms.ToTensor()])\ntrain_data = cancer_dataset('../input/train',train_csv,transform = train_transforms)\ntrain_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nmean,std = normalization_parameter(train_loader)","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1719), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1744a04382e4477586497db836a65d7b"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n                                        transforms.Resize((im_size,im_size)),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.transforms.RandomRotation(10),\n                                        transforms.RandomVerticalFlip(p=0.5),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean,std)])\ntest_transforms = transforms.Compose([\n                                        transforms.ToPILImage(),\n                                        transforms.Resize((im_size,im_size)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean,std)])\n\n#inverse normalization for image plot\n\ninv_normalize =  transforms.Normalize(\n    mean=-1*np.divide(mean,std),\n    std=1/std\n)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = cancer_dataset('../input/train',train_df,transform = train_transforms)\nval_data = cancer_dataset('../input/train',test_df,transform = test_transforms)\n\ndataloaders =  data_loader(train_data,encoder = encoder,valid_size = 0.2, batch_size = batch_size)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nimport torchvision\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchsummary import summary\nimport torch.optim as optim\nimport copy\nimport os\nimport torch\nfrom tqdm.autonotebook import tqdm\n\nimport matplotlib.pyplot as plt\n\nclass classifie(nn.Module):\n    def __init__(self,n_classes ):\n        super(classifie, self).__init__()\n        self.cnn_arch = EfficientNet.from_pretrained('efficientnet-b0')\n        self.linear1 = nn.Linear(1000,256)\n        self.relu = nn.LeakyReLU()\n        self.linear2 = nn.Linear(256,n_classes)\n        #self.softmax = nn.Softmax(dim=1)\n        self.bn = nn.BatchNorm1d(256)\n        self.dropout = nn.Dropout(0.75)\n        \n    def forward(self, input):\n        am = self.cnn_arch(input)\n        x = self.dropout(self.bn(self.relu(self.linear1(am))))\n        x = self.linear2(x)\n        return x","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclassifier = classifie(n_classes = 2).to(device)","execution_count":40,"outputs":[{"output_type":"stream","text":"Loaded pretrained weights for efficientnet-b0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function, with_statement, division\nimport copy\nimport os\nimport torch\nfrom tqdm.autonotebook import tqdm\nfrom torch.optim.lr_scheduler import _LRScheduler\nimport matplotlib.pyplot as plt\n\n\nclass LRFinder(object):\n    \"\"\"Learning rate range test.\n    The learning rate range test increases the learning rate in a pre-training run\n    between two boundaries in a linear or exponential manner. It provides valuable\n    information on how well the network can be trained over a range of learning rates\n    and what is the optimal learning rate.\n    Arguments:\n        model (torch.nn.Module): wrapped model.\n        optimizer (torch.optim.Optimizer): wrapped optimizer where the defined learning\n            is assumed to be the lower boundary of the range test.\n        criterion (torch.nn.Module): wrapped loss function.\n        device (str or torch.device, optional): a string (\"cpu\" or \"cuda\") with an\n            optional ordinal for the device type (e.g. \"cuda:X\", where is the ordinal).\n            Alternatively, can be an object representing the device on which the\n            computation will take place. Default: None, uses the same device as `model`.\n        memory_cache (boolean): if this flag is set to True, `state_dict` of model and\n            optimizer will be cached in memory. Otherwise, they will be saved to files\n            under the `cache_dir`.\n        cache_dir (string): path for storing temporary files. If no path is specified,\n            system-wide temporary directory is used.\n            Notice that this parameter will be ignored if `memory_cache` is True.\n    Example:\n        >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n        >>> lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n    Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n    fastai/lr_find: https://github.com/fastai/fastai\n    \"\"\"\n\n    def __init__(self, model, optimizer, criterion, device=None, memory_cache=True, cache_dir=None):\n        self.model = model\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.history = {\"lr\": [], \"loss\": []}\n        self.best_loss = None\n        self.memory_cache = memory_cache\n        self.cache_dir = cache_dir\n\n        # Save the original state of the model and optimizer so they can be restored if\n        # needed\n        self.model_device = next(self.model.parameters()).device\n        self.state_cacher = StateCacher(memory_cache, cache_dir=cache_dir)\n        self.state_cacher.store('model', self.model.state_dict())\n        self.state_cacher.store('optimizer', self.optimizer.state_dict())\n\n        # If device is None, use the same as the model\n        if device:\n            self.device = device\n        else:\n            self.device = self.model_device\n\n    def reset(self):\n        \"\"\"Restores the model and optimizer to their initial states.\"\"\"\n        self.model.load_state_dict(self.state_cacher.retrieve('model'))\n        self.optimizer.load_state_dict(self.state_cacher.retrieve('optimizer'))\n        self.model.to(self.model_device)\n\n    def range_test(\n        self,\n        train_loader,\n        val_loader=None,\n        end_lr=10,\n        num_iter=100,\n        step_mode=\"exp\",\n        smooth_f=0.05,\n        diverge_th=5,\n    ):\n        \"\"\"Performs the learning rate range test.\n        Arguments:\n            train_loader (torch.utils.data.DataLoader): the training set data laoder.\n            val_loader (torch.utils.data.DataLoader, optional): if `None` the range test\n                will only use the training loss. When given a data loader, the model is\n                evaluated after each iteration on that dataset and the evaluation loss\n                is used. Note that in this mode the test takes significantly longer but\n                generally produces more precise results. Default: None.\n            end_lr (float, optional): the maximum learning rate to test. Default: 10.\n            num_iter (int, optional): the number of iterations over which the test\n                occurs. Default: 100.\n            step_mode (str, optional): one of the available learning rate policies,\n                linear or exponential (\"linear\", \"exp\"). Default: \"exp\".\n            smooth_f (float, optional): the loss smoothing factor within the [0, 1[\n                interval. Disabled if set to 0, otherwise the loss is smoothed using\n                exponential smoothing. Default: 0.05.\n            diverge_th (int, optional): the test is stopped when the loss surpasses the\n                threshold:  diverge_th * best_loss. Default: 5.\n        \"\"\"\n        # Reset test results\n        self.history = {\"lr\": [], \"loss\": []}\n        self.best_loss = None\n\n        # Move the model to the proper device\n        self.model.to(self.device)\n\n        # Initialize the proper learning rate policy\n        if step_mode.lower() == \"exp\":\n            lr_schedule = ExponentialLR(self.optimizer, end_lr, num_iter)\n        elif step_mode.lower() == \"linear\":\n            lr_schedule = LinearLR(self.optimizer, end_lr, num_iter)\n        else:\n            raise ValueError(\"expected one of (exp, linear), got {}\".format(step_mode))\n\n        if smooth_f < 0 or smooth_f >= 1:\n            raise ValueError(\"smooth_f is outside the range [0, 1[\")\n\n        # Create an iterator to get data batch by batch\n        iterator = iter(train_loader)\n        for iteration in tqdm(range(num_iter)):\n            # Get a new set of inputs and labels\n            try:\n                inputs, labels = next(iterator)\n            except StopIteration:\n                iterator = iter(train_loader)\n                inputs, labels = next(iterator)\n\n            # Train on batch and retrieve loss\n            loss = self._train_batch(inputs, labels)\n            if val_loader:\n                loss = self._validate(val_loader)\n\n            # Update the learning rate\n            lr_schedule.step()\n            self.history[\"lr\"].append(lr_schedule.get_lr()[0])\n\n            # Track the best loss and smooth it if smooth_f is specified\n            if iteration == 0:\n                self.best_loss = loss\n            else:\n                if smooth_f > 0:\n                    loss = smooth_f * loss + (1 - smooth_f) * self.history[\"loss\"][-1]\n                if loss < self.best_loss:\n                    self.best_loss = loss\n\n            # Check if the loss has diverged; if it has, stop the test\n            self.history[\"loss\"].append(loss)\n            if loss > diverge_th * self.best_loss:\n                print(\"Stopping early, the loss has diverged\")\n                break\n\n        print(\"Learning rate search finished. See the graph with {finder_name}.plot()\")\n\n    def _train_batch(self, inputs, labels):\n        # Set model to training mode\n        self.model.train()\n\n        # Move data to the correct device\n        inputs = inputs.to(self.device)\n        labels = labels.to(self.device)\n\n        # Forward pass\n        self.optimizer.zero_grad()\n        outputs = self.model(inputs)\n        loss = self.criterion(outputs, labels)\n\n        # Backward pass\n        loss.backward()\n        self.optimizer.step()\n\n        return loss.item()\n\n    def _validate(self, dataloader):\n        # Set model to evaluation mode and disable gradient computation\n        running_loss = 0\n        self.model.eval()\n        with torch.no_grad():\n            for inputs, labels in dataloader:\n                # Move data to the correct device\n                inputs = inputs.to(self.device)\n                labels = labels.to(self.device)\n\n                # Forward pass and loss computation\n                outputs = self.model(inputs)\n                loss = self.criterion(outputs, labels)\n                running_loss += loss.item() * inputs.size(0)\n\n        return running_loss / len(dataloader.dataset)\n\n    def plot(self, skip_start=10, skip_end=5, log_lr=True):\n        \"\"\"Plots the learning rate range test.\n        Arguments:\n            skip_start (int, optional): number of batches to trim from the start.\n                Default: 10.\n            skip_end (int, optional): number of batches to trim from the start.\n                Default: 5.\n            log_lr (bool, optional): True to plot the learning rate in a logarithmic\n                scale; otherwise, plotted in a linear scale. Default: True.\n        \"\"\"\n\n        if skip_start < 0:\n            raise ValueError(\"skip_start cannot be negative\")\n        if skip_end < 0:\n            raise ValueError(\"skip_end cannot be negative\")\n\n        # Get the data to plot from the history dictionary. Also, handle skip_end=0\n        # properly so the behaviour is the expected\n        lrs = self.history[\"lr\"]\n        losses = self.history[\"loss\"]\n        if skip_end == 0:\n            lrs = lrs[skip_start:]\n            losses = losses[skip_start:]\n        else:\n            lrs = lrs[skip_start:-skip_end]\n            losses = losses[skip_start:-skip_end]\n\n        # Plot loss as a function of the learning rate\n        plt.plot(lrs, losses)\n        if log_lr:\n            plt.xscale(\"log\")\n        plt.xlabel(\"Learning rate\")\n        plt.ylabel(\"Loss\")\n        plt.show()\n\n\nclass LinearLR(_LRScheduler):\n    \"\"\"Linearly increases the learning rate between two boundaries over a number of\n    iterations.\n    Arguments:\n        optimizer (torch.optim.Optimizer): wrapped optimizer.\n        end_lr (float, optional): the initial learning rate which is the lower\n            boundary of the test. Default: 10.\n        num_iter (int, optional): the number of iterations over which the test\n            occurs. Default: 100.\n        last_epoch (int): the index of last epoch. Default: -1.\n    \"\"\"\n\n    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(LinearLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        curr_iter = self.last_epoch + 1\n        r = curr_iter / self.num_iter\n        return [base_lr + r * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n\n\nclass ExponentialLR(_LRScheduler):\n    \"\"\"Exponentially increases the learning rate between two boundaries over a number of\n    iterations.\n    Arguments:\n        optimizer (torch.optim.Optimizer): wrapped optimizer.\n        end_lr (float, optional): the initial learning rate which is the lower\n            boundary of the test. Default: 10.\n        num_iter (int, optional): the number of iterations over which the test\n            occurs. Default: 100.\n        last_epoch (int): the index of last epoch. Default: -1.\n    \"\"\"\n\n    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        curr_iter = self.last_epoch + 1\n        r = curr_iter / self.num_iter\n        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n\n\nclass StateCacher(object):\n    def __init__(self, in_memory, cache_dir=None):\n        self.in_memory = in_memory\n        self.cache_dir = cache_dir\n\n        if self.cache_dir is None:\n            import tempfile\n            self.cache_dir = tempfile.gettempdir()\n        else:\n            if not os.path.isdir(self.cache_dir):\n                raise ValueError('Given `cache_dir` is not a valid directory.')\n\n        self.cached = {}\n\n    def store(self, key, state_dict):\n        if self.in_memory:\n            self.cached.update({key: copy.deepcopy(state_dict)})\n        else:\n            fn = os.path.join(self.cache_dir, 'state_{}_{}.pt'.format(key, id(self)))\n            self.cached.update({key: fn})\n            torch.save(state_dict, fn)\n\n    def retrieve(self, key):\n        if key not in self.cached:\n            raise KeyError('Target {} was not cached.'.format(key))\n\n        if self.in_memory:\n            return self.cached.get(key)\n        else:\n            fn = self.cached.get(key)\n            if not os.path.exists(fn):\n                raise RuntimeError('Failed to load state in {}. File does not exist anymore.'.format(fn))\n            state_dict = torch.load(fn, map_location=lambda storage, location: storage)\n            return state_dict\n\n    def __del__(self):\n        \"\"\"Check whether there are unused cached files existing in `cache_dir` before\n        this instance being destroyed.\"\"\"\n        if self.in_memory:\n            return\n\n        for k in self.cached:\n            if os.path.exists(self.cached[k]):\n                os.remove(self.cached[k])","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_finder(model,train_loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    criterion = nn.CrossEntropyLoss()\n    optimizer_ft = optim.Adam(model.parameters(), lr=0.0000001)\n    lr_finder = LRFinder(model, optimizer_ft, criterion, device=device)\n    lr_finder.range_test(train_loader, end_lr=1, num_iter=1000)\n    lr_finder.reset()\n    lr_finder.plot()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = dataloaders['train']","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_finder(classifier,train_loader)","execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"790a620d91b84044adaa9aa2b11bb4dd"}},"metadata":{}},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  mean = torch.tensor(mean, dtype=torch.float32)\n/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  std = torch.tensor(std, dtype=torch.float32)\n","name":"stderr"},{"output_type":"stream","text":"Stopping early, the loss has diverged\nLearning rate search finished. See the graph with {finder_name}.plot()\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport matplotlib.pyplot as plt\nimport random\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch\nfrom torch import nn\n\ndef train(model,dataloaders,device,num_epochs,lr,batch_size,patience):\n    best_acc = 0.0\n    i = 0\n    phase1 = dataloaders.keys()\n    losses = list()\n    criterion = nn.CrossEntropyLoss()\n    acc = list()\n    for epoch in range(num_epochs):\n        print('Epoch:',epoch)\n        optimizer = optim.Adam(model.parameters(), lr=lr , weight_decay = 0.001)\n        lr = lr*0.9\n        for phase in phase1:\n            if phase == ' train':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n            total = 0\n            j = 0\n            for  batch_idx, (data, target) in enumerate(dataloaders[phase]):\n                data, target = Variable(data), Variable(target)\n                data = data.type(torch.FloatTensor).to(device)\n                target = target.type(torch.LongTensor).to(device)\n\n                optimizer.zero_grad()\n                output = model(data)\n                loss = criterion(output, target)\n                _, preds = torch.max(output, 1)\n                running_corrects = running_corrects + torch.sum(preds == target.data)\n                running_loss += loss.item() * data.size(0)\n                j = j+1\n                if(phase =='train'):\n                    loss.backward()\n                    optimizer.step()\n\n                if batch_idx % 100 == 0:\n                    print('{} Epoch: {}  [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tAcc: {:.6f}'.format(phase,epoch, batch_idx * len(data), len(dataloaders[phase].dataset),100. * batch_idx / len(dataloaders[phase])\n                                                                                                 , running_loss/(j*batch_size),running_corrects.double()/(j*batch_size)))\n            epoch_acc = running_corrects.double()/(len(dataloaders[phase])*batch_size)\n            epoch_loss = running_loss/(len(dataloaders[phase])*batch_size)\n            if(phase == 'train'):\n                losses.append(epoch_loss)\n                acc.append(epoch_acc)\n        print('{} Accuracy: {}'.format(phase,epoch_acc.item()))\n    return losses,acc\n\ndef train_model(model,dataloaders,encoder,lr_scheduler = None,inv_normalize = None,num_epochs=10,lr=0.0001,batch_size=8,patience = None,classes = None):\n    dataloader_train = {}\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    losses = list()\n    accuracy = list()\n    key = dataloaders.keys()\n    perform_test = False\n    for phase in key:\n        if(phase == 'test'):\n            perform_test = True\n        else:\n            dataloader_train.update([(phase,dataloaders[phase])])\n    losses,accuracy = train(model,dataloader_train,device,num_epochs,lr,batch_size,patience)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.001\ntrain_model(classifier,dataloaders,encoder,inv_normalize,num_epochs=5,lr = lr,batch_size = batch_size,patience = None,classes = classes)","execution_count":41,"outputs":[{"output_type":"stream","text":"Epoch: 0\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  mean = torch.tensor(mean, dtype=torch.float32)\n/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  std = torch.tensor(std, dtype=torch.float32)\n","name":"stderr"},{"output_type":"stream","text":"train Epoch: 0  [0/220025 (0%)]\tLoss: 0.695550 \tAcc: 0.429688\ntrain Epoch: 0  [12800/220025 (29%)]\tLoss: 0.522646 \tAcc: 0.752475\ntrain Epoch: 0  [25600/220025 (58%)]\tLoss: 0.463744 \tAcc: 0.788557\ntrain Epoch: 0  [38400/220025 (87%)]\tLoss: 0.441539 \tAcc: 0.802455\nval Epoch: 0  [0/220025 (0%)]\tLoss: 0.311815 \tAcc: 0.867188\nval Epoch: 0  [12800/220025 (29%)]\tLoss: 0.368720 \tAcc: 0.834158\nval Epoch: 0  [25600/220025 (58%)]\tLoss: 0.366278 \tAcc: 0.835704\nval Epoch: 0  [38400/220025 (87%)]\tLoss: 0.367590 \tAcc: 0.834925\nval Accuracy: 0.8330532340116279\nEpoch: 1\ntrain Epoch: 1  [0/220025 (0%)]\tLoss: 0.358228 \tAcc: 0.835938\ntrain Epoch: 1  [12800/220025 (29%)]\tLoss: 0.407007 \tAcc: 0.829749\ntrain Epoch: 1  [25600/220025 (58%)]\tLoss: 0.382400 \tAcc: 0.837531\ntrain Epoch: 1  [38400/220025 (87%)]\tLoss: 0.375855 \tAcc: 0.840350\nval Epoch: 1  [0/220025 (0%)]\tLoss: 0.282636 \tAcc: 0.875000\nval Epoch: 1  [12800/220025 (29%)]\tLoss: 0.338151 \tAcc: 0.855817\nval Epoch: 1  [25600/220025 (58%)]\tLoss: 0.338730 \tAcc: 0.856538\nval Epoch: 1  [38400/220025 (87%)]\tLoss: 0.338270 \tAcc: 0.855819\nval Accuracy: 0.854514898255814\nEpoch: 2\ntrain Epoch: 2  [0/220025 (0%)]\tLoss: 0.258580 \tAcc: 0.921875\ntrain Epoch: 2  [12800/220025 (29%)]\tLoss: 0.355259 \tAcc: 0.854115\ntrain Epoch: 2  [25600/220025 (58%)]\tLoss: 0.354095 \tAcc: 0.850280\ntrain Epoch: 2  [38400/220025 (87%)]\tLoss: 0.351296 \tAcc: 0.852237\nval Epoch: 2  [0/220025 (0%)]\tLoss: 0.404003 \tAcc: 0.804688\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-45b8cd921bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minv_normalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-57b0855b6b95>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, encoder, lr_scheduler, inv_normalize, num_epochs, lr, batch_size, patience, classes)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdataloader_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-57b0855b6b95>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, device, num_epochs, lr, batch_size, patience)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mfor\u001b[0m  \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-9fa3b551ccd9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}